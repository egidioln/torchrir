{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convex room RIR calculation\n",
    "\n",
    "{download}`Download this page as a notebook ðŸ—Ž </guides/convex_room.ipynb>`.\n",
    "\n",
    "\n",
    "Let's calculate the room impulse response (RIR) for a convex room using torchRIR. First let's define a shoebox room as a convex room, given it's vertices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchrir.geometry import ConvexRoom\n",
    "import torch\n",
    "\n",
    "torch.set_default_device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "x_size = 4.5000\n",
    "y_size = 2.1500\n",
    "z_size = 3.3000\n",
    "points = torch.tensor(\n",
    "    [\n",
    "        [-x_size, -y_size, -z_size],\n",
    "        [-x_size, -y_size, z_size],\n",
    "        [-x_size, y_size, -z_size],\n",
    "        [-x_size, y_size, z_size],\n",
    "        [x_size, -y_size, -z_size],\n",
    "        [x_size, -y_size, z_size],\n",
    "        [x_size, y_size, -z_size],\n",
    "        [x_size, y_size, z_size],\n",
    "    ],\n",
    ")\n",
    "\n",
    "shoebox_room = ConvexRoom(points.T, 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can simply visualize the room using matplotlib by calling `.plot()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shoebox_room.plot(alpha=0.35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute the RIR, we need to define a sound source. which can be done by specifying the source position in the room.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchrir.source import Source\n",
    "\n",
    "\n",
    "source = Source(position=torch.tensor([0.8, 0.8, 0.8]), intensity=2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally the impulse response can be computed by calling the `.computer_rir()` method on the room object, passing the receiver position, the sources, and the sampling frequency, along with other parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchrir.geometry import ImpulseResponseStrategies\n",
    "\n",
    "fs = 28000.0  # Hz\n",
    "rir = shoebox_room.compute_rir(\n",
    "    p=torch.tensor([0.2, 0.2, 0.2]),  # receiver position\n",
    "    s=source,\n",
    "    k=7,\n",
    "    fs=fs,\n",
    "    impulse_response_fn=ImpulseResponseStrategies.sinc,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize the RIR in the time domain and in the frequency domain using matplotlib, as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "\n",
    "\n",
    "rir = [_.cpu() for _ in rir]  # move to CPU for plotting\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(rir[1], rir[0])\n",
    "plt.xlim([0, 1])\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "H = abs(scipy.fft.fft(rir[0].numpy()))\n",
    "f = scipy.fft.fftfreq(len(H), 1 / fs)\n",
    "plt.semilogx(f[: len(f) // 2], H[: len(f) // 2])\n",
    "plt.xlim([1, fs / 2])\n",
    "plt.xlabel(\"Frequency (Hz)\")\n",
    "plt.ylabel(\"Magnitude\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The impulse response can also be heard below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "import wave\n",
    "\n",
    "with wave.open(\"_output.wav\", \"w\") as wf:\n",
    "    wf.setnchannels(1)  # Mono\n",
    "    wf.setsampwidth(2)  # 2 bytes per sample (16-bit PCM)\n",
    "    wf.setframerate(1 / (rir[1][1] - rir[1][0]).numpy())\n",
    "    wf.writeframes((rir[0].numpy() * 32767).astype(\"int16\").tobytes())\n",
    "\n",
    "IPython.display.Audio(\"_output.wav\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
